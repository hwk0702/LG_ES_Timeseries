{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1477ead4",
   "metadata": {},
   "source": [
    "# [ LG에너지 솔루션_DX_Intensive_Course ] 시계열 데이터 분석을 위한 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442ff0db",
   "metadata": {},
   "source": [
    "## 트랜스포머 기반의 시계열 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "python src/main.py \n",
    "--output_dir path/to/experiments \n",
    "--comment \"regression from Scratch\" \n",
    "--name $1_fromScratch_Regression \n",
    "--records_file Regression_records.xls \n",
    "--data_dir path/to/Datasets/Regression/$1/ \n",
    "--data_class tsra \n",
    "--pattern TRAIN \n",
    "--val_pattern TEST \n",
    "--epochs 100 \n",
    "--lr 0.001 \n",
    "--optimizer RAdam  \n",
    "--pos_encoding learnable \n",
    "--task regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89846378",
   "metadata": {},
   "outputs": [],
   "source": [
    "python src/main.py \n",
    "--output_dir experiments \n",
    "--comment \"pretraining through imputation\" \n",
    "--name $1_pretrained \n",
    "--records_file Imputation_records.xls \n",
    "--data_dir /path/to/$1/ \n",
    "--data_class tsra \n",
    "--pattern TRAIN \n",
    "--val_ratio 0.2 \n",
    "--epochs 700 \n",
    "--lr 0.001 \n",
    "--optimizer RAdam \n",
    "--batch_size 32 \n",
    "--pos_encoding learnable \n",
    "--d_model 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef339ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "python src/main.py \n",
    "--output_dir experiments \n",
    "--comment \"finetune for regression\" \n",
    "--name BeijingPM25Quality_finetuned \n",
    "--records_file Regression_records.xls \n",
    "--data_dir /path/to/Datasets/Regression/BeijingPM25Quality/ \n",
    "--data_class tsra \n",
    "--pattern TRAIN \n",
    "--val_pattern TEST  \n",
    "--epochs 200 \n",
    "--lr 0.001 \n",
    "--optimizer RAdam \n",
    "--pos_encoding learnable \n",
    "--d_model 128 \n",
    "--load_model path/to/BeijingPM25Quality_pretrained/checkpoints/model_best.pth \n",
    "--task regression \n",
    "--change_output \n",
    "--batch_size 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff69a0",
   "metadata": {},
   "source": [
    "## SETP 0. 환경 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e32035d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:17:16.819173Z",
     "start_time": "2023-06-04T11:17:12.968521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipdb in /usr/local/lib/python3.6/dist-packages (from -r ./mvts_transformer/requirements.txt (line 1)) (0.13.13)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r ./mvts_transformer/requirements.txt (line 2)) (4.62.3)\n",
      "Requirement already satisfied: xlrd in /usr/local/lib/python3.6/dist-packages (from -r ./mvts_transformer/requirements.txt (line 3)) (2.0.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r ./mvts_transformer/requirements.txt (line 4)) (1.1.5)\n",
      "Collecting xlutils\n",
      "  Downloading xlutils-2.0.0-py2.py3-none-any.whl (55 kB)\n",
      "     |████████████████████████████████| 55 kB 351 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from -r ./mvts_transformer/requirements.txt (line 6)) (0.8.9)\n",
      "Requirement already satisfied: xlwt in /usr/local/lib/python3.6/dist-packages (from -r ./mvts_transformer/requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r ./mvts_transformer/requirements.txt (line 8)) (1.7.1)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r ./mvts_transformer/requirements.txt (line 9)) (2.6.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r ./mvts_transformer/requirements.txt (line 10)) (3.3.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r ./mvts_transformer/requirements.txt (line 11)) (1.19.3)\n",
      "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.6/dist-packages (from -r ./mvts_transformer/requirements.txt (line 12)) (0.24.2)\n",
      "Requirement already satisfied: sktime==0.4.1 in /usr/local/lib/python3.6/dist-packages (from -r ./mvts_transformer/requirements.txt (line 13)) (0.4.1)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from sktime==0.4.1->-r ./mvts_transformer/requirements.txt (line 13)) (0.37.1)\n",
      "Requirement already satisfied: statsmodels>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from sktime==0.4.1->-r ./mvts_transformer/requirements.txt (line 13)) (0.12.1)\n",
      "Requirement already satisfied: tomli in /usr/local/lib/python3.6/dist-packages (from ipdb->-r ./mvts_transformer/requirements.txt (line 1)) (1.2.3)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipdb->-r ./mvts_transformer/requirements.txt (line 1)) (4.4.2)\n",
      "Requirement already satisfied: ipython<7.17.0,>=7.16.3 in /usr/local/lib/python3.6/dist-packages (from ipdb->-r ./mvts_transformer/requirements.txt (line 1)) (7.16.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r ./mvts_transformer/requirements.txt (line 4)) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->-r ./mvts_transformer/requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->-r ./mvts_transformer/requirements.txt (line 8)) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->-r ./mvts_transformer/requirements.txt (line 8)) (0.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (2.27.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (1.8.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (3.19.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (0.15.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (59.6.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (2.0.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (1.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (1.43.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r ./mvts_transformer/requirements.txt (line 10)) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r ./mvts_transformer/requirements.txt (line 10)) (3.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r ./mvts_transformer/requirements.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r ./mvts_transformer/requirements.txt (line 10)) (8.4.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit_learn->-r ./mvts_transformer/requirements.txt (line 12)) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit_learn->-r ./mvts_transformer/requirements.txt (line 12)) (3.0.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit_learn->-r ./mvts_transformer/requirements.txt (line 12)) (1.5.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.4->tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython<7.17.0,>=7.16.3->ipdb->-r ./mvts_transformer/requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython<7.17.0,>=7.16.3->ipdb->-r ./mvts_transformer/requirements.txt (line 1)) (0.7.5)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.6/dist-packages (from ipython<7.17.0,>=7.16.3->ipdb->-r ./mvts_transformer/requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ipython<7.17.0,>=7.16.3->ipdb->-r ./mvts_transformer/requirements.txt (line 1)) (3.0.24)\n",
      "Requirement already satisfied: jedi<=0.17.2,>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython<7.17.0,>=7.16.3->ipdb->-r ./mvts_transformer/requirements.txt (line 1)) (0.17.2)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython<7.17.0,>=7.16.3->ipdb->-r ./mvts_transformer/requirements.txt (line 1)) (2.11.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython<7.17.0,>=7.16.3->ipdb->-r ./mvts_transformer/requirements.txt (line 1)) (4.3.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (4.8.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (2.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (2021.10.8)\n",
      "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.11.0->sktime==0.4.1->-r ./mvts_transformer/requirements.txt (line 13)) (0.5.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (3.6.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from jedi<=0.17.2,>=0.10->ipython<7.17.0,>=7.16.3->ipdb->-r ./mvts_transformer/requirements.txt (line 1)) (0.7.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<7.17.0,>=7.16.3->ipdb->-r ./mvts_transformer/requirements.txt (line 1)) (0.2.5)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r ./mvts_transformer/requirements.txt (line 9)) (3.1.1)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython<7.17.0,>=7.16.3->ipdb->-r ./mvts_transformer/requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect->ipython<7.17.0,>=7.16.3->ipdb->-r ./mvts_transformer/requirements.txt (line 1)) (0.7.0)\n",
      "Installing collected packages: xlutils\n",
      "Successfully installed xlutils-2.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ./mvts_transformer/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3e83505a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:52:43.323135Z",
     "start_time": "2023-06-04T11:52:43.304011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:[3.6.9 (default, Dec  8 2021, 21:08:43) \n",
      "[GCC 8.4.0]].\n",
      "PyTorch version:[1.7.1].\n",
      "device:[cuda:0].\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from easydict import EasyDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "\n",
    "# from trainer import Trainer\n",
    "from mvts_transformer.src.options import Options\n",
    "from mvts_transformer.src.running import setup, pipeline_factory, validate, check_progress, NEG_METRICS\n",
    "from mvts_transformer.src.utils import utils\n",
    "from mvts_transformer.src.datasets.data import data_factory, Normalizer\n",
    "from mvts_transformer.src.datasets.datasplit import split_dataset\n",
    "from mvts_transformer.src.models.ts_transformer import model_factory\n",
    "from mvts_transformer.src.models.loss import get_loss_module\n",
    "from mvts_transformer.src.optimizers import get_optimizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#check torch version & device\n",
    "print (\"Python version:[%s].\"%(sys.version))\n",
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"device:[%s].\"%(device)) # device에 cuda:0가 프린트 된다면 GPU를 사용하는 상태입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6704d987",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T08:55:18.044041Z",
     "start_time": "2023-06-04T08:55:18.032326Z"
    }
   },
   "outputs": [],
   "source": [
    "# set random seed \n",
    "\n",
    "def set_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "random_seed = 42\n",
    "set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3d4d82",
   "metadata": {},
   "source": [
    "### SETP 1. 데이터 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00def37",
   "metadata": {},
   "source": [
    "금일 실습에서는 BeijingPM25 데이터를 활용하여 시계열 회귀를 진행합니다.\n",
    "* 해당 데이터는 연구용 시계열 데이터로 실제 데이터가 아닌 합성 데이터들로 이루어짐\n",
    "* 여러가지 데이터중 한가지 시계열 데이터를 가져와 학습 및 추론을 수행함\n",
    "* 데이터셋 출처\n",
    "    * https://webscope.sandbox.yahoo.com/catalog.php?datatype=s&did=70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "515df0dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:32:52.164172Z",
     "start_time": "2023-06-04T11:32:52.152473Z"
    }
   },
   "outputs": [],
   "source": [
    "args2 = EasyDict({\n",
    "    # for dataloader \n",
    "    'output_dir': './mvts_transformer/output',\n",
    "    'data_dir': './mvts_transformer/data/BeijingPM25Quality',\n",
    "    'name': 'pretrained',\n",
    "    'records_file': 'Imputation_records.xls',\n",
    "    \n",
    "    \n",
    "    # System\n",
    "    'print_interval': 1,\n",
    "    'gpu': 0,\n",
    "    'n_proc': -1,\n",
    "    'num_workers': 0,\n",
    "    \n",
    "    # Dataset\n",
    "    'limit_size': None,\n",
    "    'data_class': 'tsra',\n",
    "    'pattern': 'TRAIN',\n",
    "    'val_ratio': 0.2,\n",
    "    'epoch': 700,\n",
    "    'lr': 0.001,\n",
    "    'optimizer': 'RAdam',\n",
    "    'batch_size': 32,\n",
    "    'pos_encoding': 'learnable',\n",
    "    'd_model': 128\n",
    "    \n",
    "#     'root_path':'./LG_ES_Transformer/data/yahoo_S5/A2Benchmark/',\n",
    "#     'data_name':'synthetic_1.csv',\n",
    "#     'num_features':1,\n",
    "#     'make_plot':True,\n",
    "#     'test_ratio':0.6,\n",
    "#     'valid_ratio':0.1,\n",
    "#     'normal':True,\n",
    "#     'window_size':48,\n",
    "#     'batch_size':128,\n",
    "#     'slide_size':1,\n",
    "#     'forecast':True,\n",
    "#     'forecast_step':1,\n",
    "\n",
    "#     # for training\n",
    "#     'training':True,\n",
    "#     'checkpoint':'best',\n",
    "#     'cuda':True,\n",
    "#     'n_feature':1,\n",
    "#     'lr':0,\n",
    "#     'epochs':30,\n",
    "#     'step_size':5,\n",
    "#     'gamma':1.0,\n",
    "#     'version':0,\n",
    "\n",
    "#     # for gradient clipping\n",
    "#     'clip':False,\n",
    "#     'max_norm':1.0,\n",
    "    \n",
    "#     # for early stopping\n",
    "#     'early_stopping':True,\n",
    "#     'patience':300,\n",
    "#     'save_list':False,\n",
    "#     'min_epoch':0,\n",
    "\n",
    "#     # for Transformer\n",
    "#     'feature_size':256,\n",
    "#     'num_layers':1,\n",
    "#     'dropout':0.1,\n",
    "#     'nhead':8,\n",
    "#     'activation':None,\n",
    "#     'initrange':0.1,\n",
    "\n",
    "#     # for model\n",
    "#     'model':'STOC',\n",
    "#     'trend_learning':False,\n",
    "    \n",
    "#     # for testing\n",
    "#     'eval_plot':True,\n",
    "#     'anomaly_plot':True,\n",
    "#     'shuffle':False,\n",
    "#     'pred_one':False,\n",
    "\n",
    "#     # for save\n",
    "#     'experiment_name':'STOC_test'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a3bc518",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T10:59:51.870814Z",
     "start_time": "2023-06-04T10:59:51.861296Z"
    }
   },
   "outputs": [],
   "source": [
    "from mvts_transformer.src.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7df0c7eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:05:41.621938Z",
     "start_time": "2023-06-04T11:05:41.613517Z"
    }
   },
   "outputs": [],
   "source": [
    "args = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1b2eaab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:05:42.169776Z",
     "start_time": "2023-06-04T11:05:42.165807Z"
    }
   },
   "outputs": [],
   "source": [
    "args = args.parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd3b994a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:05:43.306571Z",
     "start_time": "2023-06-04T11:05:43.296457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config_filepath': None,\n",
       " 'output_dir': './output',\n",
       " 'data_dir': './data',\n",
       " 'load_model': None,\n",
       " 'resume': False,\n",
       " 'change_output': False,\n",
       " 'save_all': False,\n",
       " 'experiment_name': '',\n",
       " 'comment': '',\n",
       " 'no_timestamp': False,\n",
       " 'records_file': './records.xls',\n",
       " 'console': False,\n",
       " 'print_interval': 1,\n",
       " 'gpu': '0',\n",
       " 'n_proc': -1,\n",
       " 'num_workers': 0,\n",
       " 'seed': None,\n",
       " 'limit_size': None,\n",
       " 'test_only': None,\n",
       " 'data_class': 'weld',\n",
       " 'labels': None,\n",
       " 'test_from': None,\n",
       " 'test_ratio': 0,\n",
       " 'val_ratio': 0.2,\n",
       " 'pattern': None,\n",
       " 'val_pattern': None,\n",
       " 'test_pattern': None,\n",
       " 'normalization': 'standardization',\n",
       " 'norm_from': None,\n",
       " 'subsample_factor': None,\n",
       " 'task': 'imputation',\n",
       " 'masking_ratio': 0.15,\n",
       " 'mean_mask_length': 3,\n",
       " 'mask_mode': 'separate',\n",
       " 'mask_distribution': 'geometric',\n",
       " 'exclude_feats': None,\n",
       " 'mask_feats': '0, 1',\n",
       " 'start_hint': 0.0,\n",
       " 'end_hint': 0.0,\n",
       " 'harden': False,\n",
       " 'epochs': 400,\n",
       " 'val_interval': 2,\n",
       " 'optimizer': 'Adam',\n",
       " 'lr': 0.001,\n",
       " 'lr_step': '1000000',\n",
       " 'lr_factor': '0.1',\n",
       " 'batch_size': 64,\n",
       " 'l2_reg': 0,\n",
       " 'global_reg': False,\n",
       " 'key_metric': 'loss',\n",
       " 'freeze': False,\n",
       " 'model': 'transformer',\n",
       " 'max_seq_len': None,\n",
       " 'data_window_len': None,\n",
       " 'd_model': 64,\n",
       " 'dim_feedforward': 256,\n",
       " 'num_heads': 8,\n",
       " 'num_layers': 3,\n",
       " 'dropout': 0.1,\n",
       " 'pos_encoding': 'fixed',\n",
       " 'activation': 'gelu',\n",
       " 'normalization_layer': 'BatchNorm'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70c8f5f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:32:55.437602Z",
     "start_time": "2023-06-04T11:32:55.433021Z"
    }
   },
   "outputs": [],
   "source": [
    "args.__dict__.update(args2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8cb0425c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:32:56.233341Z",
     "start_time": "2023-06-04T11:32:56.222333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config_filepath': None,\n",
       " 'output_dir': './mvts_transformer/output',\n",
       " 'data_dir': './mvts_transformer/data/BeijingPM25Quality',\n",
       " 'load_model': None,\n",
       " 'resume': False,\n",
       " 'change_output': False,\n",
       " 'save_all': False,\n",
       " 'experiment_name': '',\n",
       " 'comment': '',\n",
       " 'no_timestamp': False,\n",
       " 'records_file': 'Imputation_records.xls',\n",
       " 'console': False,\n",
       " 'print_interval': 1,\n",
       " 'gpu': 0,\n",
       " 'n_proc': -1,\n",
       " 'num_workers': 0,\n",
       " 'seed': None,\n",
       " 'limit_size': None,\n",
       " 'test_only': None,\n",
       " 'data_class': 'tsra',\n",
       " 'labels': None,\n",
       " 'test_from': None,\n",
       " 'test_ratio': 0,\n",
       " 'val_ratio': 0.2,\n",
       " 'pattern': 'TRAIN',\n",
       " 'val_pattern': None,\n",
       " 'test_pattern': None,\n",
       " 'normalization': 'standardization',\n",
       " 'norm_from': None,\n",
       " 'subsample_factor': None,\n",
       " 'task': 'imputation',\n",
       " 'masking_ratio': 0.15,\n",
       " 'mean_mask_length': 3,\n",
       " 'mask_mode': 'separate',\n",
       " 'mask_distribution': 'geometric',\n",
       " 'exclude_feats': None,\n",
       " 'mask_feats': '0, 1',\n",
       " 'start_hint': 0.0,\n",
       " 'end_hint': 0.0,\n",
       " 'harden': False,\n",
       " 'epochs': 400,\n",
       " 'val_interval': 2,\n",
       " 'optimizer': 'RAdam',\n",
       " 'lr': 0.001,\n",
       " 'lr_step': '1000000',\n",
       " 'lr_factor': '0.1',\n",
       " 'batch_size': 32,\n",
       " 'l2_reg': 0,\n",
       " 'global_reg': False,\n",
       " 'key_metric': 'loss',\n",
       " 'freeze': False,\n",
       " 'model': 'transformer',\n",
       " 'max_seq_len': None,\n",
       " 'data_window_len': None,\n",
       " 'd_model': 128,\n",
       " 'dim_feedforward': 256,\n",
       " 'num_heads': 8,\n",
       " 'num_layers': 3,\n",
       " 'dropout': 0.1,\n",
       " 'pos_encoding': 'learnable',\n",
       " 'activation': 'gelu',\n",
       " 'normalization_layer': 'BatchNorm',\n",
       " 'name': 'pretrained',\n",
       " 'epoch': 700,\n",
       " 'initial_timestamp': '2023-06-04_11-19-41',\n",
       " 'save_dir': './mvts_transformer/output/_2023-06-04_11-19-41_Nbr/checkpoints',\n",
       " 'pred_dir': './mvts_transformer/output/_2023-06-04_11-19-41_Nbr/predictions',\n",
       " 'tensorboard_dir': './mvts_transformer/output/_2023-06-04_11-19-41_Nbr/tb_summaries'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93afb678",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:19:39.957782Z",
     "start_time": "2023-06-04T11:19:39.156640Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir ./mvts_transformer/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c6f9932",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:19:41.164258Z",
     "start_time": "2023-06-04T11:19:41.155911Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 11:19:41,160 | INFO : Stored configuration file in './mvts_transformer/output/_2023-06-04_11-19-41_Nbr'\n"
     ]
    }
   ],
   "source": [
    "config = setup(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "76183fa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:21:30.130239Z",
     "start_time": "2023-06-04T11:21:30.122628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mvts_transformer.src.datasets.data.TSRegressionArchive"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_class = data_factory[config['data_class']]\n",
    "data_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "84e4dc6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:34:25.155962Z",
     "start_time": "2023-06-04T11:32:58.614903Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11942it [00:40, 294.65it/s]\n"
     ]
    }
   ],
   "source": [
    "my_data = data_class(config['data_dir'], pattern=config['pattern'], n_proc=config['n_proc'], limit_size=config['limit_size'], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4e5766c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:36:06.375504Z",
     "start_time": "2023-06-04T11:36:06.371840Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_dim = my_data.feature_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54584b8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:36:10.845643Z",
     "start_time": "2023-06-04T11:36:10.815619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_0</th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>-18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1023.2</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>1024.5</td>\n",
       "      <td>-19.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1025.2</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11917</th>\n",
       "      <td>27.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>1026.3</td>\n",
       "      <td>-8.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11917</th>\n",
       "      <td>34.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>1026.2</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11917</th>\n",
       "      <td>31.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>1025.8</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11917</th>\n",
       "      <td>40.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>1025.5</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11917</th>\n",
       "      <td>43.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>1025.2</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286032 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dim_0  dim_1   dim_2  dim_3  dim_4   dim_5  dim_6  dim_7  dim_8\n",
       "0        4.0    7.0   300.0   77.0   -0.7  1023.0  -18.8    0.0    4.4\n",
       "0        4.0    7.0   300.0   77.0   -1.1  1023.2  -18.2    0.0    4.7\n",
       "0        5.0   10.0   300.0   73.0   -1.1  1023.5  -18.2    0.0    5.6\n",
       "0       11.0   11.0   300.0   72.0   -1.4  1024.5  -19.4    0.0    3.1\n",
       "0       12.0   12.0   300.0   72.0   -2.0  1025.2  -19.5    0.0    2.0\n",
       "...      ...    ...     ...    ...    ...     ...    ...    ...    ...\n",
       "11917   27.0   96.0  3300.0    9.0   -1.4  1026.3   -8.6    0.0    1.0\n",
       "11917   34.0   99.0  3700.0    9.0   -2.5  1026.2   -8.4    0.0    1.3\n",
       "11917   31.0   95.0  3100.0    9.0   -2.7  1025.8   -8.0    0.0    0.9\n",
       "11917   40.0   99.0  4200.0   13.0   -3.5  1025.5   -7.6    0.0    0.4\n",
       "11917   43.0  104.0  4800.0   16.0   -3.4  1025.2   -7.5    0.0    1.8\n",
       "\n",
       "[286032 rows x 9 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6d4c3d46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:36:23.032684Z",
     "start_time": "2023-06-04T11:36:23.028257Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_method = 'ShuffleSplit'\n",
    "labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5a062103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:36:39.630215Z",
     "start_time": "2023-06-04T11:36:39.625065Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = my_data\n",
    "test_indices = None  # will be converted to empty list in `split_dataset`, if also test_set_ratio == 0\n",
    "val_data = my_data\n",
    "val_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8f4e82f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:37:15.529023Z",
     "start_time": "2023-06-04T11:37:15.521798Z"
    }
   },
   "outputs": [],
   "source": [
    "if config['val_pattern']:  # used if val data come from different files / file patterns\n",
    "    val_data = data_class(config['data_dir'], pattern=config['val_pattern'], n_proc=-1, config=config)\n",
    "    val_indices = val_data.all_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5ece2648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:37:35.062075Z",
     "start_time": "2023-06-04T11:37:35.056234Z"
    }
   },
   "outputs": [],
   "source": [
    "config['val_pattern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "976122da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:38:19.152297Z",
     "start_time": "2023-06-04T11:38:19.141426Z"
    }
   },
   "outputs": [],
   "source": [
    "if config['val_ratio'] > 0:\n",
    "    train_indices, val_indices, test_indices = split_dataset(data_indices=my_data.all_IDs,\n",
    "                                                                validation_method=validation_method,\n",
    "                                                                n_splits=1,\n",
    "                                                                validation_ratio=config['val_ratio'],\n",
    "                                                                test_set_ratio=config['test_ratio'],  # used only if test_indices not explicitly specified\n",
    "                                                                test_indices=test_indices,\n",
    "                                                                random_seed=1337,\n",
    "                                                                labels=labels)\n",
    "    train_indices = train_indices[0]  # `split_dataset` returns a list of indices *per fold/split*\n",
    "    val_indices = val_indices[0]  # `split_dataset` returns a list of indices *per fold/split*\n",
    "else:\n",
    "    train_indices = my_data.all_IDs\n",
    "    if test_indices is None:\n",
    "        test_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "856d53e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:38:23.017454Z",
     "start_time": "2023-06-04T11:38:23.010370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1967,  9729, 10238, ...,   860,  8381,  3223])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bf0f6056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:38:26.707224Z",
     "start_time": "2023-06-04T11:38:26.700325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  898,  9931, 11800, ...,  2083,  1906,  7427])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0ba9db3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:38:30.975638Z",
     "start_time": "2023-06-04T11:38:30.968931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "033bd37c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:39:33.407370Z",
     "start_time": "2023-06-04T11:39:33.100825Z"
    }
   },
   "outputs": [],
   "source": [
    "normalizer = None\n",
    "if config['norm_from']:\n",
    "    with open(config['norm_from'], 'rb') as f:\n",
    "        norm_dict = pickle.load(f)\n",
    "    normalizer = Normalizer(**norm_dict)\n",
    "elif config['normalization'] is not None:\n",
    "    normalizer = Normalizer(config['normalization'])\n",
    "    my_data.feature_df.loc[train_indices] = normalizer.normalize(my_data.feature_df.loc[train_indices])\n",
    "    if not config['normalization'].startswith('per_sample'):\n",
    "        # get normalizing values from training set and store for future use\n",
    "        norm_dict = normalizer.__dict__\n",
    "        with open(os.path.join(config['output_dir'], 'normalization.pickle'), 'wb') as f:\n",
    "            pickle.dump(norm_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "if normalizer is not None:\n",
    "    if len(val_indices):\n",
    "        val_data.feature_df.loc[val_indices] = normalizer.normalize(val_data.feature_df.loc[val_indices])\n",
    "    if len(test_indices):\n",
    "        test_data.feature_df.loc[test_indices] = normalizer.normalize(test_data.feature_df.loc[test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e4ebb968",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:39:52.681274Z",
     "start_time": "2023-06-04T11:39:52.629283Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model_factory(config, my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7d5b6020",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:39:55.675557Z",
     "start_time": "2023-06-04T11:39:55.667550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSTransformerEncoder(\n",
       "  (project_inp): Linear(in_features=9, out_features=128, bias=True)\n",
       "  (pos_enc): LearnablePositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerBatchNormEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerBatchNormEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerBatchNormEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=128, out_features=9, bias=True)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8a671195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:41:13.458514Z",
     "start_time": "2023-06-04T11:41:13.453251Z"
    }
   },
   "outputs": [],
   "source": [
    "if config['global_reg']:\n",
    "    weight_decay = config['l2_reg']\n",
    "    output_reg = None\n",
    "else:\n",
    "    weight_decay = 0\n",
    "    output_reg = config['l2_reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1dc207bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:41:14.022009Z",
     "start_time": "2023-06-04T11:41:14.014694Z"
    }
   },
   "outputs": [],
   "source": [
    "optim_class = get_optimizer(config['optimizer'])\n",
    "optimizer = optim_class(model.parameters(), lr=config['lr'], weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b7159531",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:41:36.572947Z",
     "start_time": "2023-06-04T11:41:34.255575Z"
    }
   },
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "lr_step = 0  # current step index of `lr_step`\n",
    "lr = config['lr']  # current learning step\n",
    "# Load model and optimizer state\n",
    "if args.load_model:\n",
    "    model, optimizer, start_epoch = utils.load_model(model, config['load_model'], optimizer, config['resume'],\n",
    "                                                        config['change_output'],\n",
    "                                                        config['lr'],\n",
    "                                                        config['lr_step'],\n",
    "                                                        config['lr_factor'])\n",
    "model.to(device)\n",
    "\n",
    "loss_module = get_loss_module(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b8b1e8b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:42:41.748880Z",
     "start_time": "2023-06-04T11:42:41.579359Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize data generators\n",
    "dataset_class, collate_fn, runner_class = pipeline_factory(config)\n",
    "val_dataset = dataset_class(val_data, val_indices)\n",
    "\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                        batch_size=config['batch_size'],\n",
    "                        shuffle=False,\n",
    "                        num_workers=config['num_workers'],\n",
    "                        pin_memory=True,\n",
    "                        collate_fn=lambda x: collate_fn(x, max_len=model.max_len))\n",
    "\n",
    "train_dataset = dataset_class(my_data, train_indices)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                            batch_size=config['batch_size'],\n",
    "                            shuffle=True,\n",
    "                            num_workers=config['num_workers'],\n",
    "                            pin_memory=True,\n",
    "                            collate_fn=lambda x: collate_fn(x, max_len=model.max_len))\n",
    "\n",
    "trainer = runner_class(model, train_loader, device, loss_module, optimizer, l2_reg=output_reg,\n",
    "                                print_interval=config['print_interval'], console=config['console'])\n",
    "val_evaluator = runner_class(model, val_loader, device, loss_module,\n",
    "                                    print_interval=config['print_interval'], console=config['console'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1856b6f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:52:49.404042Z",
     "start_time": "2023-06-04T11:52:48.096997Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 11:52:48,106 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 0   0.0% | batch:         0 of        75\t|\tloss: 1.07261e+07\n",
      "Evaluating Epoch 0   1.3% | batch:         1 of        75\t|\tloss: 7.65159e+06\n",
      "Evaluating Epoch 0   2.7% | batch:         2 of        75\t|\tloss: 6.279e+06\n",
      "Evaluating Epoch 0   4.0% | batch:         3 of        75\t|\tloss: 6.53315e+06\n",
      "Evaluating Epoch 0   5.3% | batch:         4 of        75\t|\tloss: 6.78696e+06\n",
      "Evaluating Epoch 0   6.7% | batch:         5 of        75\t|\tloss: 1.03023e+07\n",
      "Evaluating Epoch 0   8.0% | batch:         6 of        75\t|\tloss: 1.04736e+07\n",
      "Evaluating Epoch 0   9.3% | batch:         7 of        75\t|\tloss: 6.40292e+06\n",
      "Evaluating Epoch 0  10.7% | batch:         8 of        75\t|\tloss: 7.66732e+06\n",
      "Evaluating Epoch 0  12.0% | batch:         9 of        75\t|\tloss: 6.49553e+06\n",
      "Evaluating Epoch 0  13.3% | batch:        10 of        75\t|\tloss: 7.26929e+06\n",
      "Evaluating Epoch 0  14.7% | batch:        11 of        75\t|\tloss: 8.29193e+06\n",
      "Evaluating Epoch 0  16.0% | batch:        12 of        75\t|\tloss: 6.95894e+06\n",
      "Evaluating Epoch 0  17.3% | batch:        13 of        75\t|\tloss: 8.61385e+06\n",
      "Evaluating Epoch 0  18.7% | batch:        14 of        75\t|\tloss: 7.72927e+06\n",
      "Evaluating Epoch 0  20.0% | batch:        15 of        75\t|\tloss: 7.4464e+06\n",
      "Evaluating Epoch 0  21.3% | batch:        16 of        75\t|\tloss: 7.11832e+06\n",
      "Evaluating Epoch 0  22.7% | batch:        17 of        75\t|\tloss: 7.64452e+06\n",
      "Evaluating Epoch 0  24.0% | batch:        18 of        75\t|\tloss: 6.5202e+06\n",
      "Evaluating Epoch 0  25.3% | batch:        19 of        75\t|\tloss: 1.0994e+07\n",
      "Evaluating Epoch 0  26.7% | batch:        20 of        75\t|\tloss: 7.66281e+06\n",
      "Evaluating Epoch 0  28.0% | batch:        21 of        75\t|\tloss: 8.37491e+06\n",
      "Evaluating Epoch 0  29.3% | batch:        22 of        75\t|\tloss: 8.22935e+06\n",
      "Evaluating Epoch 0  30.7% | batch:        23 of        75\t|\tloss: 7.88059e+06\n",
      "Evaluating Epoch 0  32.0% | batch:        24 of        75\t|\tloss: 6.34132e+06\n",
      "Evaluating Epoch 0  33.3% | batch:        25 of        75\t|\tloss: 6.78105e+06\n",
      "Evaluating Epoch 0  34.7% | batch:        26 of        75\t|\tloss: 6.2675e+06\n",
      "Evaluating Epoch 0  36.0% | batch:        27 of        75\t|\tloss: 8.19497e+06\n",
      "Evaluating Epoch 0  37.3% | batch:        28 of        75\t|\tloss: 7.00878e+06\n",
      "Evaluating Epoch 0  38.7% | batch:        29 of        75\t|\tloss: 7.92173e+06\n",
      "Evaluating Epoch 0  40.0% | batch:        30 of        75\t|\tloss: 7.76339e+06\n",
      "Evaluating Epoch 0  41.3% | batch:        31 of        75\t|\tloss: 6.88915e+06\n",
      "Evaluating Epoch 0  42.7% | batch:        32 of        75\t|\tloss: 1.13479e+07\n",
      "Evaluating Epoch 0  44.0% | batch:        33 of        75\t|\tloss: 5.97597e+06\n",
      "Evaluating Epoch 0  45.3% | batch:        34 of        75\t|\tloss: 7.93731e+06\n",
      "Evaluating Epoch 0  46.7% | batch:        35 of        75\t|\tloss: 5.90634e+06\n",
      "Evaluating Epoch 0  48.0% | batch:        36 of        75\t|\tloss: 5.85125e+06\n",
      "Evaluating Epoch 0  49.3% | batch:        37 of        75\t|\tloss: 6.21293e+06\n",
      "Evaluating Epoch 0  50.7% | batch:        38 of        75\t|\tloss: 8.52846e+06\n",
      "Evaluating Epoch 0  52.0% | batch:        39 of        75\t|\tloss: 8.17643e+06\n",
      "Evaluating Epoch 0  53.3% | batch:        40 of        75\t|\tloss: 1.1971e+07\n",
      "Evaluating Epoch 0  54.7% | batch:        41 of        75\t|\tloss: 5.80516e+06\n",
      "Evaluating Epoch 0  56.0% | batch:        42 of        75\t|\tloss: 7.52269e+06\n",
      "Evaluating Epoch 0  57.3% | batch:        43 of        75\t|\tloss: 8.469e+06\n",
      "Evaluating Epoch 0  58.7% | batch:        44 of        75\t|\tloss: 7.3284e+06\n",
      "Evaluating Epoch 0  60.0% | batch:        45 of        75\t|\tloss: 7.13722e+06\n",
      "Evaluating Epoch 0  61.3% | batch:        46 of        75\t|\tloss: 9.74268e+06\n",
      "Evaluating Epoch 0  62.7% | batch:        47 of        75\t|\tloss: 5.08349e+06\n",
      "Evaluating Epoch 0  64.0% | batch:        48 of        75\t|\tloss: 8.94095e+06\n",
      "Evaluating Epoch 0  65.3% | batch:        49 of        75\t|\tloss: 6.54209e+06\n",
      "Evaluating Epoch 0  66.7% | batch:        50 of        75\t|\tloss: 7.3133e+06\n",
      "Evaluating Epoch 0  68.0% | batch:        51 of        75\t|\tloss: 7.31773e+06\n",
      "Evaluating Epoch 0  69.3% | batch:        52 of        75\t|\tloss: 6.83535e+06\n",
      "Evaluating Epoch 0  70.7% | batch:        53 of        75\t|\tloss: 7.03508e+06\n",
      "Evaluating Epoch 0  72.0% | batch:        54 of        75\t|\tloss: 1.23227e+07\n",
      "Evaluating Epoch 0  73.3% | batch:        55 of        75\t|\tloss: 4.49738e+06\n",
      "Evaluating Epoch 0  74.7% | batch:        56 of        75\t|\tloss: 1.00524e+07\n",
      "Evaluating Epoch 0  76.0% | batch:        57 of        75\t|\tloss: 1.06075e+07\n",
      "Evaluating Epoch 0  77.3% | batch:        58 of        75\t|\tloss: 8.45021e+06\n",
      "Evaluating Epoch 0  78.7% | batch:        59 of        75\t|\tloss: 7.70054e+06\n",
      "Evaluating Epoch 0  80.0% | batch:        60 of        75\t|\tloss: 8.54087e+06\n",
      "Evaluating Epoch 0  81.3% | batch:        61 of        75\t|\tloss: 7.05812e+06\n",
      "Evaluating Epoch 0  82.7% | batch:        62 of        75\t|\tloss: 6.59304e+06\n",
      "Evaluating Epoch 0  84.0% | batch:        63 of        75\t|\tloss: 4.69508e+06\n",
      "Evaluating Epoch 0  85.3% | batch:        64 of        75\t|\tloss: 8.99698e+06\n",
      "Evaluating Epoch 0  86.7% | batch:        65 of        75\t|\tloss: 6.43145e+06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 11:52:49,373 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 1.265991449356079 seconds\n",
      "\n",
      "2023-06-04 11:52:49,374 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 1.2883978684743245 seconds\n",
      "2023-06-04 11:52:49,375 | INFO : Avg batch val. time: 0.017178638246324325 seconds\n",
      "2023-06-04 11:52:49,376 | INFO : Avg sample val. time: 0.0005404353475143978 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 0  88.0% | batch:        66 of        75\t|\tloss: 6.28423e+06\n",
      "Evaluating Epoch 0  89.3% | batch:        67 of        75\t|\tloss: 8.20886e+06\n",
      "Evaluating Epoch 0  90.7% | batch:        68 of        75\t|\tloss: 8.94368e+06\n",
      "Evaluating Epoch 0  92.0% | batch:        69 of        75\t|\tloss: 6.77833e+06\n",
      "Evaluating Epoch 0  93.3% | batch:        70 of        75\t|\tloss: 7.45283e+06\n",
      "Evaluating Epoch 0  94.7% | batch:        71 of        75\t|\tloss: 8.92637e+06\n",
      "Evaluating Epoch 0  96.0% | batch:        72 of        75\t|\tloss: 5.86746e+06\n",
      "Evaluating Epoch 0  97.3% | batch:        73 of        75\t|\tloss: 6.88433e+06\n",
      "Evaluating Epoch 0  98.7% | batch:        74 of        75\t|\tloss: 1.09129e+07\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'add_scalar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-270a60dc1e3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Evaluate on validation before training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m aggr_metrics_val, best_metrics, best_value = validate(val_evaluator, None, config, best_metrics,\n\u001b[0;32m----> 8\u001b[0;31m                                                         best_value, epoch=0)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmetrics_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0maggr_metrics_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/dsba/etc/2023_LG_Energysolution/230623/mvts_transformer/src/running.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(val_evaluator, tensorboard_writer, config, best_metrics, best_value, epoch)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mprint_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Epoch {} Validation Summary: '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maggr_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m \u001b[0;31m#         tensorboard_writer.add_scalar('{}/val'.format(k), v, epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mprint_str\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'{}: {:8f} | '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'add_scalar'"
     ]
    }
   ],
   "source": [
    "tensorboard_writer = SummaryWriter(config['tensorboard_dir'])\n",
    "best_value = 1e16 if config['key_metric'] in NEG_METRICS else -1e16  # initialize with +inf or -inf depending on key metric\n",
    "metrics = []  # (for validation) list of lists: for each epoch, stores metrics like loss, ...\n",
    "best_metrics = {}\n",
    "\n",
    "    # Evaluate on validation before training\n",
    "aggr_metrics_val, best_metrics, best_value = validate(val_evaluator, None, config, best_metrics,\n",
    "                                                        best_value, epoch=0)\n",
    "metrics_names, metrics_values = zip(*aggr_metrics_val.items())\n",
    "metrics.append(list(metrics_values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "43a7ae31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:52:02.182388Z",
     "start_time": "2023-06-04T11:52:02.153747Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-69780b92f919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensorboard_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/val'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "tensorboard_writer.add_scalar('{}/val'.format(k), v, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de06046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "ko",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "ko",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
